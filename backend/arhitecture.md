# ğŸ§  Audio Cleaning & Transcription Pipeline Architecture

This document outlines the architecture for a real-time audio streaming system that ingests incoming audio over WebSockets, filters and denoises it, and sends only relevant voice segments to OpenAI Whisper for transcription. The primary goal is **reducing cost and improving accuracy** by removing silence, white noise, and non-human audio before invoking the LLM.

---

## ğŸ”§ Tech Stack

- **Frontend**: WebSocket audio stream (browser/mic)
- **Backend (Python)**:
  - `websockets` / `FastAPI + WebSocket`
  - [`silero-vad`](https://github.com/snakers4/silero-vad): lightweight voice activity detection (VAD)
  - [`rnnoise`](https://github.com/xiph/rnnoise): real-time denoising
  - `ffmpeg` or `pydub`: for audio conversion and chunking
  - `openai` Python SDK: for Whisper transcription

---

## ğŸ§© System Architecture

```text
[ Mic / Audio Source (Client) ]
            â†“
    [ Audio Chunking (e.g. 1s PCM) ]
            â†“
    [ WebSocket Stream to Backend ]
            â†“
    [ Backend: Python WebSocket Handler ]
            â†“
    [ Silero VAD ]
      â”œâ”€ Not speech â†’ Drop âŒ
      â””â”€ Is speech â†’ Proceed âœ…
            â†“
    [ RNNoise Denoising ]
            â†“
    [ Optional: Convert to WAV/16kHz if needed ]
            â†“
    [ Send to OpenAI Whisper / LLM API ]
            â†“
    [ Return Transcription to Client or Store ]
```

Audio Chunks â†’ Buffer â†’ Silero VAD â†’ Speech Segments â†’ RNNoise â†’ Whisper â†’ Return Transcription
</rewritten_file>